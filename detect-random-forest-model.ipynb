{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest multiclass classifier submission\n",
    "**Author: [Carl McBride Ellis](https://www.kaggle.com/carlmcbrideellis)** ([LinkedIn](https://www.linkedin.com/in/carl-mcbride-ellis/))\n",
    "\n",
    "\n",
    "We shall be using the multiclass training data file (`Zzzs_train_multi.parquet`) from the reduced dataset [\"Zzzs: Lightweight training dataset + target\"](https://www.kaggle.com/datasets/carlmcbrideellis/zzzs-lightweight-training-dataset-target)"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import gc"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2023-11-11T15:50:22.497796Z",
     "iopub.execute_input": "2023-11-11T15:50:22.498271Z",
     "iopub.status.idle": "2023-11-11T15:50:22.988494Z",
     "shell.execute_reply.started": "2023-11-11T15:50:22.498229Z",
     "shell.execute_reply": "2023-11-11T15:50:22.987421Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# binary class data\n",
    "#train = pd.read_parquet(\"/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet\")\n",
    "\n",
    "# multiclass data\n",
    "train = pd.read_parquet(\"/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train_multi.parquet\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-11T15:50:22.990552Z",
     "iopub.execute_input": "2023-11-11T15:50:22.991039Z",
     "iopub.status.idle": "2023-11-11T15:50:37.685048Z",
     "shell.execute_reply.started": "2023-11-11T15:50:22.991006Z",
     "shell.execute_reply": "2023-11-11T15:50:37.683764Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def make_features(df):\n",
    "    # parse the timestamp and create an \"hour\" feature\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    \n",
    "    periods = 20\n",
    "    df[\"anglez\"] = abs(df[\"anglez\"])\n",
    "    df[\"anglez_diff\"] = df.groupby('series_id')['anglez'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"enmo_diff\"] = df.groupby('series_id')['enmo'].diff(periods=periods).fillna(method=\"bfill\").astype('float16')\n",
    "    df[\"anglez_rolling_mean\"] = df[\"anglez\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_mean\"] = df[\"enmo\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_max\"] = df[\"anglez\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_max\"] = df[\"enmo\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_rolling_std\"] = df[\"anglez\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_rolling_std\"] = df[\"enmo\"].rolling(periods,center=True).std().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_mean\"] = df[\"anglez_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_mean\"] = df[\"enmo_diff\"].rolling(periods,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"anglez_diff_rolling_max\"] = df[\"anglez_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    df[\"enmo_diff_rolling_max\"] = df[\"enmo_diff\"].rolling(periods,center=True).max().fillna(method=\"bfill\").fillna(method=\"ffill\").astype('float16')\n",
    "    \n",
    "    return df\n",
    "\n",
    "features = [\"hour\",\n",
    "            \"anglez\",\n",
    "            \"anglez_rolling_mean\",\n",
    "            \"anglez_rolling_max\",\n",
    "            \"anglez_rolling_std\",\n",
    "            \"anglez_diff\",\n",
    "            \"anglez_diff_rolling_mean\",\n",
    "            \"anglez_diff_rolling_max\",\n",
    "            \"enmo\",\n",
    "            \"enmo_rolling_mean\",\n",
    "            \"enmo_rolling_max\",\n",
    "            \"enmo_rolling_std\",\n",
    "            \"enmo_diff\",\n",
    "            \"enmo_diff_rolling_mean\",\n",
    "            \"enmo_diff_rolling_max\",\n",
    "           ]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-11T15:50:37.686585Z",
     "iopub.execute_input": "2023-11-11T15:50:37.686941Z",
     "iopub.status.idle": "2023-11-11T15:50:37.707052Z",
     "shell.execute_reply.started": "2023-11-11T15:50:37.686909Z",
     "shell.execute_reply": "2023-11-11T15:50:37.705826Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train   = make_features(train)\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[\"awake\"]\n",
    "\n",
    "# save some memory\n",
    "del train\n",
    "gc.collect();"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-11T15:50:37.708883Z",
     "iopub.execute_input": "2023-11-11T15:50:37.710950Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=50,\n",
    "                                    min_samples_leaf=300,\n",
    "                                    random_state=42,n_jobs=-1)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# save some memory\n",
    "del X_train, y_train\n",
    "gc.collect();"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "test  = pd.read_parquet(\"/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\")\n",
    "\n",
    "test  = make_features(test)\n",
    "\n",
    "X_test = test[features]\n",
    "\n",
    "test[\"not_awake\"] = classifier.predict_proba(X_test)[:,0]\n",
    "test[\"awake\"]     = classifier.predict_proba(X_test)[:,1]"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# smoothing the predictions\n",
    "smoothing_length = 2*230\n",
    "test[\"score\"]  = test[\"awake\"].rolling(smoothing_length,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "test[\"smooth\"] = test[\"not_awake\"].rolling(smoothing_length,center=True).mean().fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "# re-binarize\n",
    "test[\"smooth\"] = test[\"smooth\"].round()\n",
    "\n",
    "# https://stackoverflow.com/questions/73777727/how-to-mark-start-end-of-a-series-of-non-null-and-non-0-values-in-a-column-of-a\n",
    "def get_event(df):\n",
    "    lstCV = zip(df.series_id, df.smooth)\n",
    "    lstPOI = []\n",
    "    for (c, v), g in groupby(lstCV, lambda cv: \n",
    "                            (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n",
    "        llg = sum(1 for item in g)\n",
    "        if v is False: \n",
    "            lstPOI.extend([0]*llg)\n",
    "        else: \n",
    "            lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n",
    "    return lstPOI\n",
    "\n",
    "test[\"event\"] = get_event(test)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Write out a `submission.csv`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "sample_submission = test.loc[test[\"event\"] != 0][[\"series_id\",\"step\",\"event\",\"score\"]].copy().reset_index(drop=True).reset_index(names=\"row_id\")\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Related reading\n",
    "* [K. Sundararajan *et al. \"Sleep classification from wrist-worn accelerometer data using Random Forests*\", Scientific Reports volume **11**, Article number: 24 (2021)](https://www.nature.com/articles/s41598-020-79217-x.pdf)\n",
    "* [K. Sundararajan *et al. \"Supplementary Information for Article: Sleep classification from wrist-worn accelerometer data using Random Forests*\"](https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-020-79217-x/MediaObjects/41598_2020_79217_MOESM1_ESM.pdf)"
   ],
   "metadata": {}
  }
 ]
}
